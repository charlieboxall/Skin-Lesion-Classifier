{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd4ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6b354",
   "metadata": {},
   "source": [
    "CNN will be used due to its ability to recognise patterns within images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc0117",
   "metadata": {},
   "source": [
    "Convolutional layers are the core building blocks that will examen the image. Each layer from 1-3 will become more complex and use a larger number of filters to detect wider variety of patterns and high level features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032b9c8",
   "metadata": {},
   "source": [
    "Pooling layers simpify the information from the convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96eb710",
   "metadata": {},
   "source": [
    "Flatten layer prepares the data for the final classification. It takes the 3D output from the previous layers and flattens it into a single, 1D vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c178c",
   "metadata": {},
   "source": [
    "Dense layers are the final decision making layers. \"Dense(128, ...), this Dense layer has 128 neurons - each neuron is connected to all neurons from the previous flatten layer. These neurons learn to combine the features that have been extracted from the convolutional layers to make sense of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028760c",
   "metadata": {},
   "source": [
    "The dropout layer aims to prevent overfitting. If the dropout rate is 0.5, during training it will randomly disable 50% of the neurons in the previous layer to force the network to learn more robust features. It also prevents it from relying on a small number of neurons to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c725377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the CNN\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        # First Convolutional layer so small number of filters\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Second Convolutional layer - double filters\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Third Convolutional layer - double filters again\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416de2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded successfully.\n",
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chazf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.6670 - loss: 1.0740 - val_accuracy: 0.6671 - val_loss: 0.9347\n",
      "Epoch 2/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - accuracy: 0.6696 - loss: 0.9533 - val_accuracy: 0.6771 - val_loss: 0.8807\n",
      "Epoch 3/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 125ms/step - accuracy: 0.6745 - loss: 0.8916 - val_accuracy: 0.6751 - val_loss: 0.8654\n",
      "Epoch 4/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 127ms/step - accuracy: 0.6759 - loss: 0.8650 - val_accuracy: 0.6751 - val_loss: 0.8266\n",
      "Epoch 5/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 128ms/step - accuracy: 0.6893 - loss: 0.8269 - val_accuracy: 0.6964 - val_loss: 0.8710\n",
      "Epoch 6/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 127ms/step - accuracy: 0.6990 - loss: 0.8214 - val_accuracy: 0.6917 - val_loss: 0.8010\n",
      "Epoch 7/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 127ms/step - accuracy: 0.6847 - loss: 0.8682 - val_accuracy: 0.6931 - val_loss: 0.8154\n",
      "Epoch 8/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 128ms/step - accuracy: 0.7067 - loss: 0.7857 - val_accuracy: 0.7091 - val_loss: 0.7772\n",
      "Epoch 9/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 129ms/step - accuracy: 0.7218 - loss: 0.7479 - val_accuracy: 0.7004 - val_loss: 0.8175\n",
      "Epoch 10/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 288ms/step - accuracy: 0.7238 - loss: 0.7415 - val_accuracy: 0.7184 - val_loss: 0.7450\n",
      "Epoch 11/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.7365 - loss: 0.6924 - val_accuracy: 0.7137 - val_loss: 0.7491\n",
      "Epoch 12/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.7435 - loss: 0.6817 - val_accuracy: 0.7237 - val_loss: 0.7716\n",
      "Epoch 13/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 137ms/step - accuracy: 0.7565 - loss: 0.6542 - val_accuracy: 0.7370 - val_loss: 0.7466\n",
      "Epoch 14/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 131ms/step - accuracy: 0.7653 - loss: 0.6203 - val_accuracy: 0.7230 - val_loss: 0.7868\n",
      "Epoch 15/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.7832 - loss: 0.5837 - val_accuracy: 0.7270 - val_loss: 0.7449\n",
      "Epoch 16/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 134ms/step - accuracy: 0.7917 - loss: 0.5532 - val_accuracy: 0.7270 - val_loss: 0.8045\n",
      "Epoch 17/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 131ms/step - accuracy: 0.7956 - loss: 0.5268 - val_accuracy: 0.7364 - val_loss: 0.7831\n",
      "Epoch 18/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 129ms/step - accuracy: 0.8091 - loss: 0.4991 - val_accuracy: 0.7290 - val_loss: 0.8886\n",
      "Epoch 19/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 131ms/step - accuracy: 0.8126 - loss: 0.4995 - val_accuracy: 0.7330 - val_loss: 0.8115\n",
      "Epoch 20/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 129ms/step - accuracy: 0.8255 - loss: 0.4586 - val_accuracy: 0.7290 - val_loss: 0.8197\n",
      "Epoch 21/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - accuracy: 0.8381 - loss: 0.4233 - val_accuracy: 0.7357 - val_loss: 0.9296\n",
      "Epoch 22/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 127ms/step - accuracy: 0.8506 - loss: 0.3943 - val_accuracy: 0.7304 - val_loss: 0.9822\n",
      "Epoch 23/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 133ms/step - accuracy: 0.8588 - loss: 0.3682 - val_accuracy: 0.7270 - val_loss: 1.0856\n",
      "Epoch 24/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 131ms/step - accuracy: 0.8686 - loss: 0.3327 - val_accuracy: 0.7224 - val_loss: 1.0454\n",
      "Epoch 25/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 132ms/step - accuracy: 0.8796 - loss: 0.3103 - val_accuracy: 0.7344 - val_loss: 1.1715\n",
      "\n",
      "Model training completed.\n",
      "Test loss: 0.7084\n",
      "Test accuracy: 0.7319\n",
      "\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    print(\"Loading preprocessed data...\")\n",
    "    try:\n",
    "        # Normalise whilst loading in\n",
    "        x_train = np.load(\"../data/processed/x_train.npy\") / 255.0\n",
    "        y_train = np.load(\"../data/processed/y_train.npy\")\n",
    "        x_val = np.load(\"../data/processed/x_val.npy\") / 255.0\n",
    "        y_val = np.load(\"../data/processed/y_val.npy\")\n",
    "        x_test = np.load(\"../data/processed/x_test.npy\") / 255.0\n",
    "        y_test = np.load(\"../data/processed/y_test.npy\")\n",
    "        print(\"Data loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: One or more .npy file(s) could not be found.\")\n",
    "\n",
    "    # Extract neccessities for building model\n",
    "    img_size = x_train.shape[1]\n",
    "    num_classes = len(np.unique(np.concatenate([y_train, y_val, y_test])))\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "\n",
    "    # Build model\n",
    "    model = build_cnn(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(learning_rate = 0.001),\n",
    "        loss = \"sparse_categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = 10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nStarting model training...\")\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"\\nModel training completed.\")\n",
    "\n",
    "    # Evaluate model\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {loss:.4f}\")\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    model.save('../model/skin_lesion_classifier_model.keras')\n",
    "    print(\"\\nModel saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
